{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import torch\n",
    "from glob import glob\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from torch_lr_finder import LRFinder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2xxxx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def freeze_all(model_params):\n",
    "    for param in model_params:\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_all(model_params):\n",
    "    for param in model_params:\n",
    "        param.requires_grad = True\n",
    "\n",
    "def get_trainable(model_params):\n",
    "    return (p for p in model_params if p.requires_grad)\n",
    "\n",
    "def load_image(filename) :\n",
    "    img = Image.open(filename)\n",
    "    img = img.convert('RGB')\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Zhou/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (4): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (5): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "resnet.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "filenames = glob('./datasets/images/*.jpg')\n",
    "\n",
    "classes = set()\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load the images and get the classnames from the image path\n",
    "for image in filenames:\n",
    "    class_name = image.rsplit(\"\\\\\", 1)[1].rsplit('_', 1)[0]\n",
    "    classes.add(class_name)\n",
    "    img = load_image(image)\n",
    "\n",
    "    data.append(img)\n",
    "    labels.append(class_name)\n",
    "\n",
    "# convert classnames to indices\n",
    "class2idx = {cl: idx for idx, cl in enumerate(classes)}\n",
    "labels = torch.Tensor(list(map(lambda x: class2idx[x], labels))).long()\n",
    "\n",
    "data = list(zip(data, labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class PetDataset(Dataset):\n",
    "    \"Dataset to serve individual images to our model\"\n",
    "\n",
    "    def __init__(self, data, transforms=None):\n",
    "        self.data = data\n",
    "        self.len = len(data)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self.data[index]\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "# Since the data is not split into train and validation datasets we have to\n",
    "# make sure that when splitting between train and val that all classes are represented in both\n",
    "class Databasket():\n",
    "    \"Helper class to ensure equal distribution of classes in both train and validation datasets\"\n",
    "\n",
    "    def __init__(self, data, num_cl, val_split=0.2, train_transforms=None, val_transforms=None):\n",
    "        class_values = [[] for x in range(num_cl)]\n",
    "\n",
    "        # create arrays for each class type\n",
    "        for d in data:\n",
    "            class_values[d[1].item()].append(d)\n",
    "\n",
    "        self.train_data = []\n",
    "        self.val_data = []\n",
    "\n",
    "        # put (1-val_split) of the images of each class into the train dataset\n",
    "        # and val_split of the images into the validation dataset\n",
    "        for class_dp in class_values:\n",
    "            split_idx = int(len(class_dp)*(1-val_split))\n",
    "            self.train_data += class_dp[:split_idx]\n",
    "            self.val_data += class_dp[split_idx:]\n",
    "\n",
    "        self.train_ds = PetDataset(self.train_data, transforms=train_transforms)\n",
    "        self.val_ds = PetDataset(self.val_data, transforms=val_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Apply transformations to the train dataset\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# apply the same transformations to the validation set, with the exception of the\n",
    "# randomized transformation. We want the validation set to be consistent\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "])\n",
    "\n",
    "databasket = Databasket(data, len(classes), val_split=0.2, train_transforms=train_transforms, val_transforms=val_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "bn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)\n",
    "\n",
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    \"Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`.\"\n",
    "    def __init__(self, sz=None):\n",
    "        \"Output will be 2*sz or 2 if sz is None\"\n",
    "        super(AdaptiveConcatPool2d, self).__init__()\n",
    "        self.output_size = sz or 1\n",
    "        self.ap = nn.AdaptiveAvgPool2d(self.output_size)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(self.output_size)\n",
    "\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "\n",
    "def head_blocks(in_dim, p, out_dim, activation=None):\n",
    "    \"Basic Linear block\"\n",
    "    layers = [\n",
    "        nn.BatchNorm1d(in_dim),\n",
    "        nn.Dropout(p),\n",
    "        nn.Linear(in_dim, out_dim)\n",
    "    ]\n",
    "\n",
    "    if activation is not None:\n",
    "        layers.append(activation)\n",
    "\n",
    "    return layers\n",
    "\n",
    "def create_head(nf, nc, bn_final=False):\n",
    "    \"Model head that takes in 'nf' features and outputs 'nc' classes\"\n",
    "    pool = AdaptiveConcatPool2d()\n",
    "    layers = [pool, nn.Flatten()]\n",
    "    layers += head_blocks(nf, 0.25, 512, nn.ReLU(inplace=True))\n",
    "    layers += head_blocks(512, 0.5, nc)\n",
    "\n",
    "    if bn_final:\n",
    "        layers.append(nn.BatchNorm1d(nc, momentum=0.01))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def requires_grad(layer):\n",
    "    \"Determines whether 'layer' requires gradients\"\n",
    "    ps = list(layer.parameters())\n",
    "    if not ps: return None\n",
    "    return ps[0].requires_grad\n",
    "\n",
    "def cnn_model(model, nc, bn_final=False, init=nn.init.kaiming_normal_):\n",
    "    \"Creates a model using a pretrained 'model' and appends a new head to it with 'nc' outputs\"\n",
    "\n",
    "    # remove dense and freeze everything\n",
    "    body = nn.Sequential(*list(model.children())[:-2])\n",
    "    head = create_head(1024, nc, bn_final)\n",
    "\n",
    "    model = nn.Sequential(body, head)\n",
    "\n",
    "    # freeze the resnet34 base of the model\n",
    "    freeze_all(model[0].parameters())\n",
    "\n",
    "    # initialize the weights of the head\n",
    "    for child in model[1].children():\n",
    "        if isinstance(child, nn.Module) and (not isinstance(child, bn_types)) and requires_grad(child):\n",
    "            init(child.weight)\n",
    "\n",
    "    return model\n",
    "\n",
    "num_classes = len(classes)\n",
    "model = cnn_model(resnet, num_classes, bn_final=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (4): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (5): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (7): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (1): Sequential(\n    (0): AdaptiveConcatPool2d(\n      (ap): AdaptiveAvgPool2d(output_size=1)\n      (mp): AdaptiveMaxPool2d(output_size=1)\n    )\n    (1): Flatten(start_dim=1, end_dim=-1)\n    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=1024, out_features=512, bias=True)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5, inplace=False)\n    (8): Linear(in_features=512, out_features=37, bias=True)\n    (9): BatchNorm1d(37, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n  )\n)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "train_indices = list(range(len(databasket.train_ds)))\n",
    "test_indices = list(range(len(databasket.val_ds)))\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "# Basic dataloader to retrieve mini-batches from the datasets\n",
    "train_loader = DataLoader(databasket.train_ds, batch_size=64, sampler=train_sampler, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(databasket.val_ds, batch_size=64, sampler=test_sampler, shuffle=False, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# We don't actually use the learning rate here. It's set to 1e-7 so that the LR Finder\n",
    "# starts at 1e-7\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-7,  weight_decay=1e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37c52f46d49d449ebd6fbcb1bfee76b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 4.05E-03\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(<AxesSubplot:xlabel='Learning rate', ylabel='Loss'>, 0.004046831450787376)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# used to find the ideal LR for our model training\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(train_loader, end_lr=3, num_iter=100)\n",
    "lr_finder.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# A one cycle LR scheduler (https://arxiv.org/abs/1708.07120)\n",
    "# max_lr is derived from the lr_finder plot\n",
    "# epochs must match the amount of epochs you will run\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=5e-2, pct_start=0.3, steps_per_epoch=len(train_loader), epochs=15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Accuracy: 50.52 percent, Validation Accuracy: 80.19 percent, Train Loss: 2.3520721376583142, Validation Loss: 0.71703040599823\n",
      "Epoch 1: Train Accuracy: 64.98 percent, Validation Accuracy: 88.37 percent, Train Loss: 1.3515092320339654, Validation Loss: 0.2075306475162506\n",
      "Epoch 2: Train Accuracy: 75.15 percent, Validation Accuracy: 91.08 percent, Train Loss: 0.8221590419610342, Validation Loss: 0.02257710136473179\n",
      "Epoch 3: Train Accuracy: 79.56 percent, Validation Accuracy: 92.49 percent, Train Loss: 0.6663081777352159, Validation Loss: 0.5721853971481323\n",
      "Epoch 4: Train Accuracy: 82.98 percent, Validation Accuracy: 92.90 percent, Train Loss: 0.5260290074092085, Validation Loss: 0.007689070887863636\n",
      "Epoch 5: Train Accuracy: 84.20 percent, Validation Accuracy: 92.70 percent, Train Loss: 0.46544604291838987, Validation Loss: 0.17267511785030365\n",
      "Epoch 6: Train Accuracy: 86.33 percent, Validation Accuracy: 92.83 percent, Train Loss: 0.4062679986799917, Validation Loss: 0.08092427253723145\n",
      "Epoch 7: Train Accuracy: 87.31 percent, Validation Accuracy: 94.05 percent, Train Loss: 0.3786789119564077, Validation Loss: 0.026526788249611855\n",
      "Epoch 8: Train Accuracy: 88.80 percent, Validation Accuracy: 94.05 percent, Train Loss: 0.3476083741713596, Validation Loss: 0.08907002210617065\n",
      "Epoch 9: Train Accuracy: 88.80 percent, Validation Accuracy: 93.58 percent, Train Loss: 0.3333992422908865, Validation Loss: 0.5972843766212463\n",
      "Epoch 10: Train Accuracy: 89.61 percent, Validation Accuracy: 93.91 percent, Train Loss: 0.30376650000451716, Validation Loss: 0.0758000984787941\n",
      "Epoch 11: Train Accuracy: 91.02 percent, Validation Accuracy: 93.64 percent, Train Loss: 0.2817937308742154, Validation Loss: 0.24756915867328644\n",
      "Epoch 12: Train Accuracy: 90.04 percent, Validation Accuracy: 93.64 percent, Train Loss: 0.2968002770056007, Validation Loss: 0.12394975870847702\n",
      "Epoch 13: Train Accuracy: 90.39 percent, Validation Accuracy: 93.98 percent, Train Loss: 0.2858610113942495, Validation Loss: 0.0031177732162177563\n",
      "Epoch 14: Train Accuracy: 90.70 percent, Validation Accuracy: 93.98 percent, Train Loss: 0.2767176053697063, Validation Loss: 0.02786986529827118\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "model.to(device)\n",
    "\n",
    "def train(epochs, scheduler, optimizer, model):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        n_correct = 0\n",
    "\n",
    "        # use dropouts and batchnorms\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            #zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_acc = 100. * n_correct / len(databasket.train_ds)\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        n_val_correct = 0\n",
    "        val_loss = 0\n",
    "\n",
    "        # disable batchnorm and dropouts\n",
    "        model.eval()\n",
    "        # don't calculate gradient\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                inputs, labels = batch\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                val_loss = criterion(outputs, labels).item()\n",
    "\n",
    "                n_val_correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "\n",
    "\n",
    "\n",
    "        val_acc = 100. * n_val_correct / len(databasket.val_ds)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print('Epoch %s: Train Accuracy: %.2f percent, Validation Accuracy: %.2f percent, Train Loss: %s, Validation Loss: %s'\n",
    "              % (epoch, train_acc, val_acc, train_loss, val_loss))\n",
    "\n",
    "train(15, scheduler, optimizer, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': 15,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, './models/oxford_animal_frozen_1.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "unfreeze_all(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Accuracy: 91.24 percent, Validation Accuracy: 93.85 percent, Train Loss: 0.27277076484695556, Validation Loss: 0.024077819660305977\n",
      "Epoch 1: Train Accuracy: 90.66 percent, Validation Accuracy: 93.91 percent, Train Loss: 0.2717720132361176, Validation Loss: 0.33396223187446594\n",
      "Epoch 2: Train Accuracy: 90.73 percent, Validation Accuracy: 93.85 percent, Train Loss: 0.27425866870469945, Validation Loss: 0.1529480665922165\n",
      "Epoch 3: Train Accuracy: 90.53 percent, Validation Accuracy: 93.91 percent, Train Loss: 0.27261625871222506, Validation Loss: 0.09938407689332962\n",
      "Epoch 4: Train Accuracy: 91.10 percent, Validation Accuracy: 93.58 percent, Train Loss: 0.265178584283398, Validation Loss: 0.06859380006790161\n"
     ]
    }
   ],
   "source": [
    "# discriminative learning rate for fine tuning\n",
    "optimizer = optim.Adam([\n",
    "        {\"params\": model[0].parameters(), \"lr\": 1e-7},\n",
    "        {\"params\": model[1].parameters(), \"lr\": 1e-7}\n",
    "    ],  weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=(1e-6,1e-3), pct_start=0.8, steps_per_epoch=len(train_loader), epochs=5)\n",
    "train(5, scheduler, optimizer, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}