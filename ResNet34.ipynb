{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from glob import glob\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from torch_lr_finder import LRFinder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2xxxx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def freeze_all(model_params):\n",
    "    for param in model_params:\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_all(model_params):\n",
    "    for param in model_params:\n",
    "        param.requires_grad = True\n",
    "\n",
    "def get_trainable(model_params):\n",
    "    return (p for p in model_params if p.requires_grad)\n",
    "\n",
    "def load_image(filename) :\n",
    "    img = Image.open(filename)\n",
    "    img = img.convert('RGB')\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Zhou/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (4): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (5): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "resnet.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "filenames = glob('./datasets/images/*.jpg')\n",
    "\n",
    "classes = set()\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load the images and get the classnames from the image path\n",
    "for image in filenames:\n",
    "    class_name = image.rsplit(\"\\\\\", 1)[1].rsplit('_', 1)[0]\n",
    "    classes.add(class_name)\n",
    "    img = load_image(image)\n",
    "\n",
    "    data.append(img)\n",
    "    labels.append(class_name)\n",
    "\n",
    "# convert classnames to indices\n",
    "class2idx = {cl: idx for idx, cl in enumerate(classes)}\n",
    "labels = torch.Tensor(list(map(lambda x: class2idx[x], labels))).long()\n",
    "\n",
    "data = list(zip(data, labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class PetDataset(Dataset):\n",
    "    \"Dataset to serve individual images to our model\"\n",
    "\n",
    "    def __init__(self, data, transforms=None):\n",
    "        self.data = data\n",
    "        self.len = len(data)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self.data[index]\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "# Since the data is not split into train and validation datasets we have to\n",
    "# make sure that when splitting between train and val that all classes are represented in both\n",
    "class Databasket():\n",
    "    \"Helper class to ensure equal distribution of classes in both train and validation datasets\"\n",
    "\n",
    "    def __init__(self, data, num_cl, val_split=0.2, train_transforms=None, val_transforms=None):\n",
    "        class_values = [[] for x in range(num_cl)]\n",
    "\n",
    "        # create arrays for each class type\n",
    "        for d in data:\n",
    "            class_values[d[1].item()].append(d)\n",
    "\n",
    "        self.train_data = []\n",
    "        self.val_data = []\n",
    "\n",
    "        # put (1-val_split) of the images of each class into the train dataset\n",
    "        # and val_split of the images into the validation dataset\n",
    "        for class_dp in class_values:\n",
    "            split_idx = int(len(class_dp)*(1-val_split))\n",
    "            self.train_data += class_dp[:split_idx]\n",
    "            self.val_data += class_dp[split_idx:]\n",
    "\n",
    "        self.train_ds = PetDataset(self.train_data, transforms=train_transforms)\n",
    "        self.val_ds = PetDataset(self.val_data, transforms=val_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Apply transformations to the train dataset\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# apply the same transformations to the validation set, with the exception of the\n",
    "# randomized transformation. We want the validation set to be consistent\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "])\n",
    "\n",
    "databasket = Databasket(data, len(classes), val_split=0.2, train_transforms=train_transforms, val_transforms=val_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "bn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)\n",
    "\n",
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    \"Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`.\"\n",
    "    def __init__(self, sz=None):\n",
    "        \"Output will be 2*sz or 2 if sz is None\"\n",
    "        super(AdaptiveConcatPool2d, self).__init__()\n",
    "        self.output_size = sz or 1\n",
    "        self.ap = nn.AdaptiveAvgPool2d(self.output_size)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(self.output_size)\n",
    "\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "\n",
    "def head_blocks(in_dim, p, out_dim, activation=None):\n",
    "    \"Basic Linear block\"\n",
    "    layers = [\n",
    "        nn.BatchNorm1d(in_dim),\n",
    "        nn.Dropout(p),\n",
    "        nn.Linear(in_dim, out_dim)\n",
    "    ]\n",
    "\n",
    "    if activation is not None:\n",
    "        layers.append(activation)\n",
    "\n",
    "    return layers\n",
    "\n",
    "def create_head(nf, nc, bn_final=False):\n",
    "    \"Model head that takes in 'nf' features and outputs 'nc' classes\"\n",
    "    pool = AdaptiveConcatPool2d()\n",
    "    layers = [pool, nn.Flatten()]\n",
    "    layers += head_blocks(nf, 0.25, 512, nn.ReLU(inplace=True))\n",
    "    layers += head_blocks(512, 0.5, nc)\n",
    "\n",
    "    if bn_final:\n",
    "        layers.append(nn.BatchNorm1d(nc, momentum=0.01))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def requires_grad(layer):\n",
    "    \"Determines whether 'layer' requires gradients\"\n",
    "    ps = list(layer.parameters())\n",
    "    if not ps: return None\n",
    "    return ps[0].requires_grad\n",
    "\n",
    "def cnn_model(model, nc, bn_final=False, init=nn.init.kaiming_normal_):\n",
    "    \"Creates a model using a pretrained 'model' and appends a new head to it with 'nc' outputs\"\n",
    "\n",
    "    # remove dense and freeze everything\n",
    "    body = nn.Sequential(*list(model.children())[:-2])\n",
    "    head = create_head(1024, nc, bn_final)\n",
    "\n",
    "    model = nn.Sequential(body, head)\n",
    "\n",
    "    # freeze the resnet34 base of the model\n",
    "    freeze_all(model[0].parameters())\n",
    "\n",
    "    # initialize the weights of the head\n",
    "    for child in model[1].children():\n",
    "        if isinstance(child, nn.Module) and (not isinstance(child, bn_types)) and requires_grad(child):\n",
    "            init(child.weight)\n",
    "\n",
    "    return model\n",
    "\n",
    "num_classes = len(classes)\n",
    "model = cnn_model(resnet, num_classes, bn_final=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (4): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (5): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (7): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (1): Sequential(\n    (0): AdaptiveConcatPool2d(\n      (ap): AdaptiveAvgPool2d(output_size=1)\n      (mp): AdaptiveMaxPool2d(output_size=1)\n    )\n    (1): Flatten(start_dim=1, end_dim=-1)\n    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=1024, out_features=512, bias=True)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5, inplace=False)\n    (8): Linear(in_features=512, out_features=37, bias=True)\n    (9): BatchNorm1d(37, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n  )\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_indices = list(range(len(databasket.train_ds)))\n",
    "test_indices = list(range(len(databasket.val_ds)))\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "# Basic dataloader to retrieve mini-batches from the datasets\n",
    "train_loader = DataLoader(databasket.train_ds, batch_size=64, sampler=train_sampler, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(databasket.val_ds, batch_size=64, sampler=test_sampler, shuffle=False, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# We don't actually use the learning rate here. It's set to 1e-7 so that the LR Finder\n",
    "# starts at 1e-7\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-7,  weight_decay=1e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "664acf291b984b098c1470997fcb0410"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Soft\\Anaconda3\\envs\\Pytorch19\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 4.82E-03\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(<AxesSubplot:xlabel='Learning rate', ylabel='Loss'>, 0.004815502291562608)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# used to find the ideal LR for our model training\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(train_loader, end_lr=3, num_iter=100)\n",
    "lr_finder.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# A one cycle LR scheduler (https://arxiv.org/abs/1708.07120)\n",
    "# max_lr is derived from the lr_finder plot\n",
    "# epochs must match the amount of epochs you will run\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=5e-2, pct_start=0.3, steps_per_epoch=len(train_loader), epochs=15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Accuracy: 50.63 percent, Validation Accuracy: 71.94 percent, Train Loss: 2.4317609187095397, Validation Loss: 0.36865612864494324\n",
      "Epoch 1: Train Accuracy: 63.95 percent, Validation Accuracy: 87.42 percent, Train Loss: 1.463510726728747, Validation Loss: 0.23692968487739563\n",
      "Epoch 2: Train Accuracy: 75.08 percent, Validation Accuracy: 90.87 percent, Train Loss: 0.8783955663763067, Validation Loss: 0.1817208081483841\n",
      "Epoch 3: Train Accuracy: 79.95 percent, Validation Accuracy: 91.28 percent, Train Loss: 0.6539779869459008, Validation Loss: 0.059473466128110886\n",
      "Epoch 4: Train Accuracy: 83.23 percent, Validation Accuracy: 92.16 percent, Train Loss: 0.5190494291244014, Validation Loss: 0.2684873640537262\n",
      "Epoch 5: Train Accuracy: 85.59 percent, Validation Accuracy: 92.70 percent, Train Loss: 0.4489728114617768, Validation Loss: 0.017531288787722588\n",
      "Epoch 6: Train Accuracy: 86.08 percent, Validation Accuracy: 93.17 percent, Train Loss: 0.4177297563642584, Validation Loss: 0.03945808857679367\n",
      "Epoch 7: Train Accuracy: 87.01 percent, Validation Accuracy: 93.10 percent, Train Loss: 0.3858102798782369, Validation Loss: 0.09765370190143585\n",
      "Epoch 8: Train Accuracy: 88.46 percent, Validation Accuracy: 92.77 percent, Train Loss: 0.34710935991938396, Validation Loss: 0.15112611651420593\n",
      "Epoch 9: Train Accuracy: 89.04 percent, Validation Accuracy: 93.17 percent, Train Loss: 0.32778619790589936, Validation Loss: 0.16943958401679993\n",
      "Epoch 10: Train Accuracy: 89.68 percent, Validation Accuracy: 93.04 percent, Train Loss: 0.3042562928411268, Validation Loss: 0.08323056250810623\n",
      "Epoch 11: Train Accuracy: 90.54 percent, Validation Accuracy: 92.97 percent, Train Loss: 0.2925318457106108, Validation Loss: 0.01396958064287901\n",
      "Epoch 12: Train Accuracy: 89.70 percent, Validation Accuracy: 93.10 percent, Train Loss: 0.3009906664330472, Validation Loss: 0.3684863746166229\n",
      "Epoch 13: Train Accuracy: 91.34 percent, Validation Accuracy: 93.24 percent, Train Loss: 0.2653530943457798, Validation Loss: 0.6442444920539856\n",
      "Epoch 14: Train Accuracy: 91.02 percent, Validation Accuracy: 93.24 percent, Train Loss: 0.2636922349532445, Validation Loss: 0.3315085768699646\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "model.to(device=device)\n",
    "\n",
    "def train(epochs, scheduler, optimizer, model):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        n_correct = 0\n",
    "\n",
    "        # use dropouts and batchnorms\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            #zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_acc = 100. * n_correct / len(databasket.train_ds)\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        n_val_correct = 0\n",
    "        val_loss = 0\n",
    "\n",
    "        # disable batchnorm and dropouts\n",
    "        model.eval()\n",
    "        # don't calculate gradient\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                inputs, labels = batch\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                val_loss = criterion(outputs, labels).item()\n",
    "\n",
    "                n_val_correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "\n",
    "\n",
    "\n",
    "        val_acc = 100. * n_val_correct / len(databasket.val_ds)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print('Epoch %s: Train Accuracy: %.2f percent, Validation Accuracy: %.2f percent, Train Loss: %s, Validation Loss: %s'\n",
    "              % (epoch, train_acc, val_acc, train_loss, val_loss))\n",
    "\n",
    "train(15, scheduler, optimizer, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "# torch.save({\n",
    "#             'epoch': 15,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             }, './models/model.pt')\n",
    "\n",
    "scripted_module = torch.jit.script(model)\n",
    "# Export full jit version model (not compatible mobile interpreter), leave it here for comparison\n",
    "scripted_module.save(\"./models/model.pt\")\n",
    "# Export mobile interpreter version model (compatible with mobile interpreter)\n",
    "optimized_scripted_module = optimize_for_mobile(scripted_module)\n",
    "optimized_scripted_module._save_for_lite_interpreter(\"./models/model.ptl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "unfreeze_all(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Accuracy: 91.02 percent, Validation Accuracy: 93.51 percent, Train Loss: 0.2684774543008497, Validation Loss: 0.16541019082069397\n",
      "Epoch 1: Train Accuracy: 90.92 percent, Validation Accuracy: 93.17 percent, Train Loss: 0.26848066173573976, Validation Loss: 0.013428757898509502\n",
      "Epoch 2: Train Accuracy: 91.14 percent, Validation Accuracy: 93.17 percent, Train Loss: 0.2620091492770821, Validation Loss: 0.057621683925390244\n",
      "Epoch 3: Train Accuracy: 90.80 percent, Validation Accuracy: 93.10 percent, Train Loss: 0.28454816309354636, Validation Loss: 0.39206311106681824\n",
      "Epoch 4: Train Accuracy: 91.68 percent, Validation Accuracy: 93.37 percent, Train Loss: 0.24570791960083027, Validation Loss: 0.3465922474861145\n"
     ]
    }
   ],
   "source": [
    "# discriminative learning rate for fine tuning\n",
    "optimizer = optim.Adam([\n",
    "        {\"params\": model[0].parameters(), \"lr\": 1e-7},\n",
    "        {\"params\": model[1].parameters(), \"lr\": 1e-7}\n",
    "    ],  weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=(1e-6,1e-3), pct_start=0.8, steps_per_epoch=len(train_loader), epochs=5)\n",
    "train(5, scheduler, optimizer, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}